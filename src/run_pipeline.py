# src/run_pipeline.py
from data_processing import process_all_files
from vectorize_documents import LawChromaDB
from config import DATA_PROCESSED_DIR
import os


def run_full_pipeline():
    """è¿è¡Œå®Œæ•´çš„æ•°æ®å¤„ç†ç®¡é“"""
    print("ğŸš€ å¼€å§‹æ•°æ®å¤„ç†å’Œå‘é‡åŒ–...")

    # 1. å¤„ç†åŸå§‹æ•°æ®ï¼ˆæŒ‰æ¡æ¬¾åˆ‡åˆ†ï¼‰
    print("1. å¤„ç†åŸå§‹Markdownæ–‡ä»¶ï¼ˆæŒ‰æ¡æ¬¾åˆ‡åˆ†ï¼‰...")
    json_file = process_all_files()

    if not json_file:
        print("âŒ æ•°æ®å¤„ç†å¤±è´¥")
        return

    # æ£€æŸ¥JSONæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(json_file):
        print(f"âŒ JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
        return

    # 2. å‘é‡åŒ–æ–‡æ¡£
    print("\n2. å‘é‡åŒ–æ–‡æ¡£...")
    law_db = LawChromaDB()
    law_db.create_collection("chinese_laws")

    # æ£€æŸ¥é›†åˆæ˜¯å¦å·²æœ‰æ•°æ®
    has_data, message = law_db.check_collection_status()
    if has_data:
        print(f"ğŸ“Š å½“å‰é›†åˆçŠ¶æ€: {message}")
        user_input = input("ğŸ”„ é›†åˆå·²æœ‰æ•°æ®ï¼Œæ˜¯å¦é‡æ–°æ·»åŠ ï¼Ÿ(y/n): ")
        if user_input.lower() not in ['y', 'yes', 'æ˜¯']:
            print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            return
        else:
            # æ¸…ç©ºç°æœ‰é›†åˆ
            law_db.clear_collection()
            law_db.create_collection("chinese_laws")

    # è¯¢é—®æ‰¹æ¬¡å¤§å°
    try:
        batch_size = int(input("ğŸ“¦ è¯·è¾“å…¥æ‰¹æ¬¡å¤§å° (æ¨è 500-1000): ") or "500")
    except:
        batch_size = 500

    print(f"ğŸ”§ ä½¿ç”¨æ‰¹æ¬¡å¤§å°: {batch_size}")

    success = law_db.add_laws_from_json(
        f"{DATA_PROCESSED_DIR}/laws_processed.json",
        batch_size=batch_size
    )

    if success:
        # 3. æ£€æŸ¥ç»“æœ
        count = law_db.collection.count()
        print(f"\nâœ… æ•°æ®å¤„ç†å’Œå‘é‡åŒ–å®Œæˆï¼")
        print(f"ğŸ“Š å‘é‡æ•°æ®åº“ä¸­çš„æ¡æ¬¾æ•°é‡: {count}")
    else:
        print("âŒ å‘é‡åŒ–å¤±è´¥")


if __name__ == "__main__":
    run_full_pipeline()